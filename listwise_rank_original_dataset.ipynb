{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "\n",
    "from scipy   import sparse\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk import *\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from adarank import AdaRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(text):\n",
    "    \n",
    "    if pd.isna(text):\n",
    "        return ' - '\n",
    "        \n",
    "    text = text.lower() + ' '\n",
    "\n",
    "    text = text.replace('/' , ' / ')\n",
    "    text = text.replace('.' , ' . ')\n",
    "    text = text.replace(',' , ' , ')\n",
    "    text = text.replace('-' , ' - ')\n",
    "    text = text.replace('^' , ' ^ ')\n",
    "\n",
    "    text = re.sub(r'[  ]', r' ', text)\n",
    "    \n",
    "    text = text.replace('ser ' , 'serum ')\n",
    "    text = text.replace('plas ', 'plasma ')\n",
    "    text = text.replace('bld ' , 'blood ')\n",
    "    text = text.replace('fld ' , 'fluid ')\n",
    "    text = text.replace('synv ', 'synovial ')\n",
    "    text = text.replace('plr ' , 'pleural ')\n",
    "    text = text.replace('bpu ' , 'blood product unit ')\n",
    "\n",
    "    text = [word for word in text.split() if word not in corpus.stopwords.words('english')]\n",
    "    return ' '.join([word for word in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\"glucose in blood\", \"bilirubin in plasma\", \"white blood cells count\"]\n",
    "\n",
    "df = pd.read_excel(\"base_data.xlsx\")[['Query id','f0','f1','f2','f3','Y']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['f0'] = df['f0'].apply(lambda f: process(f))\n",
    "df['f1'] = df['f1'].apply(lambda f: process(f))\n",
    "df['f2'] = df['f2'].apply(lambda f: process(f))\n",
    "df['f3'] = df['f3'].apply(lambda f: process(f))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_l_norm(doc, query_word_ids):\n",
    "    doc_l_norm = 0\n",
    "    \n",
    "    for word_id in query_word_ids:\n",
    "        word_tfidf  = doc[(0,word_id)]\n",
    "        doc_l_norm += pow(word_tfidf,2)\n",
    "        \n",
    "    doc_l_norm = np.sqrt(doc_l_norm)\n",
    "    return doc_l_norm\n",
    "\n",
    "def normalize_vector(doc, query_word_ids):\n",
    "    l_norm = get_l_norm(doc, query_word_ids)\n",
    "    return [doc[(0,word_id)] / l_norm if l_norm else 0 for word_id in query_word_ids]\n",
    "\n",
    "def get_doc_cos_score(doc, query):\n",
    "    return sum([doc[i] * query[i] for i in range(len(doc))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(queries) + 1):\n",
    "\n",
    "    query = queries[i-1]\n",
    "\n",
    "    tfidf_f0 = TfidfVectorizer()\n",
    "    tfidf_f1 = TfidfVectorizer()\n",
    "    tfidf_f2 = TfidfVectorizer()\n",
    "    tfidf_f3 = TfidfVectorizer()\n",
    "    \n",
    "    vectorized_f0 = tfidf_f0.fit_transform(df[df[\"Query id\"] == i]['f0'])\n",
    "    vectorized_f1 = tfidf_f1.fit_transform(df[df[\"Query id\"] == i]['f1'])\n",
    "    vectorized_f2 = tfidf_f2.fit_transform(df[df[\"Query id\"] == i]['f2'])\n",
    "    vectorized_f3 = tfidf_f3.fit_transform(df[df[\"Query id\"] == i]['f3'])\n",
    "\n",
    "    vectorized_features = [vectorized_f0, vectorized_f1, vectorized_f2, vectorized_f3]\n",
    "\n",
    "    query_f0 = tfidf_f0.transform([query])\n",
    "    query_f1 = tfidf_f1.transform([query])\n",
    "    query_f2 = tfidf_f2.transform([query])\n",
    "    query_f3 = tfidf_f3.transform([query])\n",
    "\n",
    "    vectorized_query_per_feature = [query_f0, query_f1, query_f2, query_f3]\n",
    "\n",
    "    for vectorized_feature, feature_vectorized_query, feature_id in zip(vectorized_features, vectorized_query_per_feature, [\"f0\",\"f1\",\"f2\",\"f3\"]):\n",
    "        query_word_ids   = feature_vectorized_query.indices\n",
    "        norm_query       = normalize_vector(feature_vectorized_query, query_word_ids)\n",
    "        documents_scores = [get_doc_cos_score(normalize_vector(vectorized_feature[doc_id], query_word_ids), norm_query) for doc_id in range(0,vectorized_features[0].shape[0])]\n",
    "        \n",
    "        df.loc[df[\"Query id\"] == i, feature_id] = documents_scores\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"f0\"] = pd.to_numeric(df[\"f0\"])\n",
    "df[\"f1\"] = pd.to_numeric(df[\"f1\"])\n",
    "df[\"f2\"] = pd.to_numeric(df[\"f2\"])\n",
    "df[\"f3\"] = pd.to_numeric(df[\"f3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x1, x1_te, y1, y1_te =  train_test_split(df[df[\"Query id\"]==1][[\"Query id\", \"f0\", \"f1\", \"f2\", \"f3\"]], df[df[\"Query id\"]==1][\"Y\"], test_size = .15)\n",
    "x2, x2_te, y2, y2_te =  train_test_split(df[df[\"Query id\"]==2][[\"Query id\", \"f0\", \"f1\", \"f2\", \"f3\"]], df[df[\"Query id\"]==2][\"Y\"], test_size = .15)\n",
    "x3, x3_te, y3, y3_te =  train_test_split(df[df[\"Query id\"]==3][[\"Query id\", \"f0\", \"f1\", \"f2\", \"f3\"]], df[df[\"Query id\"]==3][\"Y\"], test_size = .15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.concat([x1,x2,x3], axis=0)\n",
    "x_te = pd.concat([x1_te,x2_te,x3_te], axis=0) \n",
    "y = pd.concat([y1,y2,y3], axis=0) \n",
    "y_te = pd.concat([y1_te,y2_te,y3_te], axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qid = np.array([1]*len(x1) + [2]*len(x2) + [3]*len(x3))\n",
    "y   = np.array(y)\n",
    "x_sparse = sparse.csr_matrix(np.array(x[[\"f0\", \"f1\", \"f2\", \"f3\"]])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AdaRank(verbose=True)\n",
    "model.fit(x_sparse,y,qid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qid_t = np.array([1]*len(x1_te) + [2]*len(x2_te) + [3]*len(x3_te))\n",
    "y_te  = np.array(y_te)\n",
    "x_te_sparse = sparse.csr_matrix(np.array(x_te[[\"f0\", \"f1\", \"f2\", \"f3\"]])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_te_sparse, None)\n",
    "print(\"The NDGC for each of the queries is respectively:\",model.evaluate(y_te, pred, qid_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_general = 0\n",
    "n_general   = 0\n",
    "\n",
    "mae_values = [0,0,0,0,0]\n",
    "n_values   = [0,0,0,0,0]\n",
    "\n",
    "for real_val, pred_val in zip(y_te, pred):\n",
    "    mae_values[real_val] += abs(real_val - pred_val)\n",
    "    n_values[real_val]   += 1\n",
    "\n",
    "for i, (mae, n) in enumerate(zip(mae_values, n_values)):\n",
    "    print(\"The MAE for queries with rank\",i,\"is:\")\n",
    "    if n == 0:\n",
    "        print(\"No test queries with that rank\")\n",
    "    else:\n",
    "        print(mae / n)\n",
    "        mae_general += mae / n\n",
    "        n_general   += 1\n",
    "    \n",
    "print(\"The overall MAE is:\")\n",
    "print(mae_general/n_general)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_general = 0\n",
    "n_general   = 0\n",
    "\n",
    "mse_values = [0,0,0,0,0]\n",
    "n_values   = [0,0,0,0,0]\n",
    "\n",
    "for real_val, pred_val in zip(y_te, pred):\n",
    "    mse_values[real_val] += pow(real_val - pred_val, 2)\n",
    "    n_values[real_val]   += 1\n",
    "\n",
    "for i, (mse, n) in enumerate(zip(mse_values, n_values)):\n",
    "    print(\"The MSE for queries with rank\",i,\"is:\")\n",
    "    if n == 0:\n",
    "        print(\"No test queries with that rank\")\n",
    "    else:\n",
    "        print(mse / n)\n",
    "        mse_general += mse / n\n",
    "        n_general   += 1\n",
    "    \n",
    "print(\"The overall MSE is:\")\n",
    "print(mse_general/n_general)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_te['Y_real'] = y_te\n",
    "x_te['Y_pred'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_te[x_te[\"Query id\"]==1].sort_values(by=['Y_pred'], ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_te[x_te[\"Query id\"]==2].sort_values(by=['Y_pred'], ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_te[x_te[\"Query id\"]==3].sort_values(by=['Y_pred'], ascending=False).head(20)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e1b2a8d64108191b5344c9ef157fce075759b55ed5353a43c30a4151c87eade3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
